{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e611461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26cdb665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.2314, 0.1961, 0.0000,\n",
      "          0.0000, 0.1961, 0.0706, 0.1255, 0.2314, 0.2314, 0.2314, 0.2314,\n",
      "          0.2314, 0.0549, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.9922, 0.7020, 0.0784,\n",
      "          0.4039, 0.9686, 0.8863, 0.9216, 0.9922, 0.9961, 0.9922, 0.9922,\n",
      "          0.9922, 0.6980, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.6039, 0.9922, 0.9922, 0.9922,\n",
      "          0.9961, 0.9922, 0.9922, 0.9922, 0.8706, 0.6863, 0.6824, 0.6824,\n",
      "          0.6824, 0.2745, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1843, 0.8941, 0.9922, 0.9922, 0.8706,\n",
      "          0.4588, 0.4588, 0.3412, 0.0745, 0.0471, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.6118, 0.9608, 0.4941, 0.3765, 0.0549,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1490, 1.0000, 0.9451, 0.1176, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.5020, 0.9765, 0.5490, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0510, 0.8353, 0.8549, 0.0588, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0941, 0.9020, 0.8902, 0.0824, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3020, 0.9922, 0.9059, 0.4196, 0.3843, 0.3843, 0.0902,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3922, 0.9961, 0.7686, 0.8706, 0.9961, 0.9961, 0.6980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0824, 0.1529, 0.0000, 0.0706, 0.1529, 0.8980, 0.9922,\n",
      "          0.3569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4196, 0.9922,\n",
      "          0.6157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.7255, 0.9294,\n",
      "          0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.5686, 0.9922, 0.4627,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1451, 0.6392, 0.9961, 0.8980, 0.2353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.2275,\n",
      "          0.0471, 0.1373, 0.6039, 0.8784, 0.9529, 0.7961, 0.1569, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4667, 0.9922,\n",
      "          0.8745, 0.9922, 0.9922, 0.6863, 0.2235, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.8353,\n",
      "          0.7176, 0.4588, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]) torch.Size([64])\n",
      "Iter-0; D_loss: 1.596374273300171; G_loss: 2.21364426612854\n",
      "Iter-1000; D_loss: 0.005788523703813553; G_loss: 8.442850112915039\n",
      "Iter-2000; D_loss: 0.0028234715573489666; G_loss: 8.809467315673828\n",
      "Iter-3000; D_loss: 0.02578173391520977; G_loss: 5.689117431640625\n",
      "Iter-4000; D_loss: 0.19349071383476257; G_loss: 5.645480632781982\n",
      "Iter-5000; D_loss: 0.24757060408592224; G_loss: 5.200473785400391\n",
      "Iter-6000; D_loss: 0.5310072302818298; G_loss: 3.6568081378936768\n",
      "Iter-7000; D_loss: 0.32809045910835266; G_loss: 3.7595343589782715\n",
      "Iter-8000; D_loss: 0.6223044395446777; G_loss: 2.9218809604644775\n",
      "Iter-9000; D_loss: 0.6394878029823303; G_loss: 2.5433287620544434\n",
      "Iter-10000; D_loss: 0.7677819728851318; G_loss: 2.624406099319458\n",
      "Iter-11000; D_loss: 0.59682697057724; G_loss: 2.668696880340576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12000; D_loss: 0.711113452911377; G_loss: 2.401885509490967\n",
      "Iter-13000; D_loss: 0.7005552649497986; G_loss: 2.4120309352874756\n",
      "Iter-14000; D_loss: 0.6816340088844299; G_loss: 2.4768097400665283\n",
      "Iter-15000; D_loss: 0.8199543356895447; G_loss: 2.2225887775421143\n",
      "Iter-16000; D_loss: 0.6136703491210938; G_loss: 2.3213813304901123\n",
      "Iter-17000; D_loss: 0.5786684155464172; G_loss: 2.3334426879882812\n",
      "Iter-18000; D_loss: 0.5918607711791992; G_loss: 1.89707350730896\n",
      "Iter-19000; D_loss: 0.6433102488517761; G_loss: 2.105242967605591\n",
      "Iter-20000; D_loss: 0.699147641658783; G_loss: 2.294600486755371\n",
      "Iter-21000; D_loss: 0.5932392477989197; G_loss: 2.135253667831421\n",
      "Iter-22000; D_loss: 0.6063427925109863; G_loss: 1.9805829524993896\n",
      "Iter-23000; D_loss: 0.686589241027832; G_loss: 2.307128667831421\n",
      "Iter-24000; D_loss: 0.6429980993270874; G_loss: 1.9668774604797363\n",
      "Iter-25000; D_loss: 0.7193344831466675; G_loss: 2.2326083183288574\n",
      "Iter-26000; D_loss: 0.7233313918113708; G_loss: 2.3596489429473877\n",
      "Iter-27000; D_loss: 0.4508369565010071; G_loss: 2.646127223968506\n",
      "Iter-28000; D_loss: 0.6220252513885498; G_loss: 2.3064873218536377\n",
      "Iter-29000; D_loss: 0.7654686570167542; G_loss: 2.124677896499634\n",
      "Iter-30000; D_loss: 0.7485764622688293; G_loss: 2.05592942237854\n",
      "Iter-31000; D_loss: 0.5368112325668335; G_loss: 2.4383935928344727\n",
      "Iter-32000; D_loss: 0.6460190415382385; G_loss: 2.4212491512298584\n",
      "Iter-33000; D_loss: 0.8510050773620605; G_loss: 2.446383237838745\n",
      "Iter-34000; D_loss: 0.7735433578491211; G_loss: 2.418674945831299\n",
      "Iter-35000; D_loss: 0.6349509954452515; G_loss: 2.545531749725342\n",
      "Iter-36000; D_loss: 0.650641918182373; G_loss: 2.4661953449249268\n",
      "Iter-37000; D_loss: 0.6949112415313721; G_loss: 2.284942865371704\n",
      "Iter-38000; D_loss: 0.7594212293624878; G_loss: 2.6847174167633057\n",
      "Iter-39000; D_loss: 0.38653528690338135; G_loss: 3.10874342918396\n",
      "Iter-40000; D_loss: 0.8494776487350464; G_loss: 2.262911558151245\n",
      "Iter-41000; D_loss: 0.594181478023529; G_loss: 2.393747329711914\n",
      "Iter-42000; D_loss: 0.5713602900505066; G_loss: 2.889007091522217\n",
      "Iter-43000; D_loss: 0.6057694554328918; G_loss: 2.286898136138916\n",
      "Iter-44000; D_loss: 0.581851065158844; G_loss: 2.1842942237854004\n",
      "Iter-45000; D_loss: 0.6890794634819031; G_loss: 2.062453508377075\n",
      "Iter-46000; D_loss: 0.6408509612083435; G_loss: 2.7635254859924316\n",
      "Iter-47000; D_loss: 0.4785369634628296; G_loss: 2.3404128551483154\n",
      "Iter-48000; D_loss: 0.5159041881561279; G_loss: 2.8315200805664062\n",
      "Iter-49000; D_loss: 0.5267996191978455; G_loss: 2.445143222808838\n",
      "Iter-50000; D_loss: 0.5379614233970642; G_loss: 2.60878324508667\n",
      "Iter-51000; D_loss: 0.5938143730163574; G_loss: 2.4082705974578857\n",
      "Iter-52000; D_loss: 0.7115820646286011; G_loss: 2.256232261657715\n",
      "Iter-53000; D_loss: 0.47453951835632324; G_loss: 2.5968704223632812\n",
      "Iter-54000; D_loss: 0.6588215827941895; G_loss: 2.3472793102264404\n",
      "Iter-55000; D_loss: 0.4388175904750824; G_loss: 2.1230902671813965\n",
      "Iter-56000; D_loss: 0.6531354188919067; G_loss: 2.1629672050476074\n",
      "Iter-57000; D_loss: 0.517527163028717; G_loss: 2.320833444595337\n",
      "Iter-58000; D_loss: 0.7168896794319153; G_loss: 2.1440255641937256\n",
      "Iter-59000; D_loss: 0.5935084819793701; G_loss: 2.574981451034546\n",
      "Iter-60000; D_loss: 0.6845186352729797; G_loss: 2.0370054244995117\n",
      "Iter-61000; D_loss: 0.5162729024887085; G_loss: 2.5689308643341064\n",
      "Iter-62000; D_loss: 0.7337037324905396; G_loss: 3.00761342048645\n",
      "Iter-63000; D_loss: 0.7014551162719727; G_loss: 2.4800615310668945\n",
      "Iter-64000; D_loss: 0.7057058811187744; G_loss: 2.404693126678467\n",
      "Iter-65000; D_loss: 0.555804431438446; G_loss: 1.985326886177063\n",
      "Iter-66000; D_loss: 0.6388031244277954; G_loss: 2.304551124572754\n",
      "Iter-67000; D_loss: 0.5578958988189697; G_loss: 1.8337767124176025\n",
      "Iter-68000; D_loss: 0.7664186954498291; G_loss: 2.394970178604126\n",
      "Iter-69000; D_loss: 0.5948473215103149; G_loss: 2.8698818683624268\n",
      "Iter-70000; D_loss: 0.5205342173576355; G_loss: 2.2832791805267334\n",
      "Iter-71000; D_loss: 0.5366723537445068; G_loss: 2.451895236968994\n",
      "Iter-72000; D_loss: 0.5238552689552307; G_loss: 2.732804298400879\n",
      "Iter-73000; D_loss: 0.632032036781311; G_loss: 2.6107378005981445\n",
      "Iter-74000; D_loss: 0.5622114539146423; G_loss: 2.7051472663879395\n",
      "Iter-75000; D_loss: 0.5227140188217163; G_loss: 2.224602460861206\n",
      "Iter-76000; D_loss: 0.5434481501579285; G_loss: 2.2887134552001953\n",
      "Iter-77000; D_loss: 0.6806823015213013; G_loss: 2.548577070236206\n",
      "Iter-78000; D_loss: 0.5572800040245056; G_loss: 1.9432721138000488\n",
      "Iter-79000; D_loss: 0.6869527101516724; G_loss: 2.660245895385742\n",
      "Iter-80000; D_loss: 0.5521283149719238; G_loss: 2.372523069381714\n",
      "Iter-81000; D_loss: 0.8347154259681702; G_loss: 2.229069709777832\n",
      "Iter-82000; D_loss: 0.5198780298233032; G_loss: 2.1861464977264404\n",
      "Iter-83000; D_loss: 0.7392299175262451; G_loss: 2.7499444484710693\n",
      "Iter-84000; D_loss: 0.6461871266365051; G_loss: 2.2578365802764893\n",
      "Iter-85000; D_loss: 0.5355637669563293; G_loss: 2.4048593044281006\n",
      "Iter-86000; D_loss: 0.6768616437911987; G_loss: 2.325322151184082\n",
      "Iter-87000; D_loss: 0.637104332447052; G_loss: 1.985039472579956\n",
      "Iter-88000; D_loss: 0.48939090967178345; G_loss: 1.9871350526809692\n",
      "Iter-89000; D_loss: 0.6959631443023682; G_loss: 2.2921128273010254\n",
      "Iter-90000; D_loss: 0.5529389977455139; G_loss: 2.276431083679199\n",
      "Iter-91000; D_loss: 0.595046877861023; G_loss: 2.2331910133361816\n",
      "Iter-92000; D_loss: 0.5604938864707947; G_loss: 2.1665890216827393\n",
      "Iter-93000; D_loss: 0.6488901376724243; G_loss: 2.3511435985565186\n",
      "Iter-94000; D_loss: 0.5981540679931641; G_loss: 2.2073633670806885\n",
      "Iter-95000; D_loss: 0.5633333921432495; G_loss: 2.221881866455078\n",
      "Iter-96000; D_loss: 0.6042226552963257; G_loss: 2.6780879497528076\n",
      "Iter-97000; D_loss: 0.5987554788589478; G_loss: 2.1026039123535156\n",
      "Iter-98000; D_loss: 0.4563789367675781; G_loss: 2.156205177307129\n",
      "Iter-99000; D_loss: 0.6002723574638367; G_loss: 2.66945743560791\n"
     ]
    }
   ],
   "source": [
    "train_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataset_mnist, val_dataset_mnist = random_split(train_dataset_mnist, [55000, 5000])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader_mnist = DataLoader(train_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "val_loader_mnist = DataLoader(val_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader_mnist = DataLoader(test_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "X_temp, y_temp = next(iter(train_loader_mnist))\n",
    "\n",
    "print(X_temp[2], y_temp.shape)\n",
    "\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "X_dim = 28*28\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
    "\n",
    "\n",
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z):\n",
    "    h = F.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = torch.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n",
    "\n",
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = F.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = torch.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params\n",
    "\n",
    "\n",
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size, 1))\n",
    "zeros_label = Variable(torch.zeros(mb_size, 1))\n",
    "\n",
    "\n",
    "for it in range(100000): \n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    X, _ = next(iter(train_loader_mnist))\n",
    "    X = X.view(-1, 784)\n",
    "    X = Variable(X)\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z)\n",
    "    D_real = D(X)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    #D_loss_real = F.binary_cross_entropy(D_real, ones_label)\n",
    "    #D_loss_fake = F.binary_cross_entropy(D_fake, zeros_label)\n",
    "    #D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss = -torch.mean(torch.log(D_real) + torch.log(1. - D_fake))\n",
    "    \n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    #G_loss = F.binary_cross_entropy(D_fake, ones_label)\n",
    "    G_loss = -torch.mean(torch.log(D_fake))\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        samples = G(z).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('original100k/'):\n",
    "            os.makedirs('original100k/')\n",
    "\n",
    "        plt.savefig('original100k/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "        c += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf325d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
