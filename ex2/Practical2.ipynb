{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2363cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "torch.manual_seed(42)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d42f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('NO GPU AVAILABLE ERROR')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72165de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torchvision.models.alexnet(pretrained = False)\n",
    "pretrained_alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    torchvision.transforms.Resize((63,63)),\n",
    "    alexnet,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "finetune_model = nn.Sequential(\n",
    "    torchvision.transforms.Resize((63,63)),\n",
    "    pretrained_alexnet,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "featureextract_model = copy.deepcopy(finetune_model)\n",
    "\n",
    "# freeze feature extraction (13 layers)\n",
    "for i, param in enumerate(featureextract_model.parameters()):\n",
    "    if i < 13:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c68bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, optimizer, loss_fn, train_loader, val_loader, model, name):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(data)\n",
    "            loss = loss_fn(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(f\"{name} Loss/train\", loss, epoch)\n",
    "            optimizer.zero_grad()\n",
    "            print(\n",
    "                f'\\rEpoch {epoch+1} [{i+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "                end=''\n",
    "            )\n",
    "\n",
    "        print('\\n*************************************')\n",
    "        print('Validation the model after epoch:', epoch)\n",
    "        accuracy(model, val_loader, epoch, f\"{name} Accuracy/validation\")\n",
    "\n",
    "def accuracy(model, data_loader, epoch, name):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, (data, labels) in enumerate(data_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(data)\n",
    "            for i in range(len(labels)):\n",
    "                pr = torch.argmax(pred[i], dim=-1)\n",
    "                if pr == labels[i]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        print(correct, total, correct/total)\n",
    "        writer.add_scalar(name, correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fd33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "finetune_model.to(device)\n",
    "featureextract_model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3935d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet from scratch\n",
      "Epoch 1 [45/45] - Loss: 2.3019835948944094\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "512 5000 0.1024\n",
      "Epoch 2 [45/45] - Loss: 1.9955395460128784\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "841 5000 0.1682\n",
      "Epoch 3 [45/45] - Loss: 1.8838280439376836\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "1353 5000 0.2706\n",
      "Epoch 4 [45/45] - Loss: 1.6800491809844978\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "1544 5000 0.3088\n",
      "Epoch 5 [45/45] - Loss: 1.5578992366790771\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "2018 5000 0.4036\n",
      "Epoch 6 [45/45] - Loss: 1.4129625558853153\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "2319 5000 0.4638\n",
      "Epoch 7 [45/45] - Loss: 1.3021799325942993\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "2614 5000 0.5228\n",
      "Epoch 8 [45/45] - Loss: 1.2155286073684692\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "2724 5000 0.5448\n",
      "Epoch 9 [45/45] - Loss: 1.1148571968078613\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "2926 5000 0.5852\n",
      "Epoch 10 [45/45] - Loss: 1.0566095113754272\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "2972 5000 0.5944\n",
      "Epoch 11 [45/45] - Loss: 0.8510261774063111\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "3064 5000 0.6128\n",
      "Epoch 12 [45/45] - Loss: 0.8987488746643066\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3153 5000 0.6306\n",
      "Epoch 13 [45/45] - Loss: 0.9080716967582703\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3099 5000 0.6198\n",
      "Epoch 14 [45/45] - Loss: 0.7081090807914734\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "3131 5000 0.6262\n",
      "Epoch 15 [45/45] - Loss: 0.7032959461212158\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3137 5000 0.6274\n",
      "Epoch 16 [45/45] - Loss: 0.60712915658950815\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "3182 5000 0.6364\n",
      "Epoch 17 [45/45] - Loss: 0.53764134645462046\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "3213 5000 0.6426\n",
      "Epoch 18 [45/45] - Loss: 0.59166890382766723\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "3134 5000 0.6268\n",
      "Epoch 19 [45/45] - Loss: 0.42268759012222293\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "3148 5000 0.6296\n",
      "Epoch 20 [45/45] - Loss: 0.37432935833930974\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "3211 5000 0.6422\n",
      "Test Accuracy\n",
      "6294 10000 0.6294\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet from scratch')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, model, \"Alexnet\")\n",
    "print('Test Accuracy')\n",
    "accuracy(model, test_loader, 0, \"Alexnet Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281d000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet using Fine-Tuning\n",
      "Epoch 1 [45/45] - Loss: 2.0327751636505127\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "1159 5000 0.2318\n",
      "Epoch 2 [45/45] - Loss: 1.6401226520538334\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "2019 5000 0.4038\n",
      "Epoch 3 [45/45] - Loss: 1.3341715335845947\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "2561 5000 0.5122\n",
      "Epoch 4 [45/45] - Loss: 1.2036085128784187\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "2822 5000 0.5644\n",
      "Epoch 5 [45/45] - Loss: 0.9623289108276367\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "3225 5000 0.645\n",
      "Epoch 6 [45/45] - Loss: 0.8623090982437134\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "3328 5000 0.6656\n",
      "Epoch 7 [45/45] - Loss: 0.7087350487709045\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "3569 5000 0.7138\n",
      "Epoch 8 [45/45] - Loss: 0.6801514029502869\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "3601 5000 0.7202\n",
      "Epoch 9 [45/45] - Loss: 0.6684660911560059\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "3756 5000 0.7512\n",
      "Epoch 10 [45/45] - Loss: 0.51860272884368947\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "3782 5000 0.7564\n",
      "Epoch 11 [45/45] - Loss: 0.49089697003364563\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "3797 5000 0.7594\n",
      "Epoch 12 [45/45] - Loss: 0.45055156946182254\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3801 5000 0.7602\n",
      "Epoch 13 [45/45] - Loss: 0.32831981778144836\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3788 5000 0.7576\n",
      "Epoch 14 [45/45] - Loss: 0.28048244118690497\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "3800 5000 0.76\n",
      "Epoch 15 [45/45] - Loss: 0.25512021780014048\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3719 5000 0.7438\n",
      "Epoch 16 [45/45] - Loss: 0.19610582292079926\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "3772 5000 0.7544\n",
      "Epoch 17 [45/45] - Loss: 0.17282156646251678\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "3755 5000 0.751\n",
      "Epoch 18 [45/45] - Loss: 0.15755294263362885\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "3887 5000 0.7774\n",
      "Epoch 19 [45/45] - Loss: 0.16571742296218872\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "3797 5000 0.7594\n",
      "Epoch 20 [45/45] - Loss: 0.24365152418613434\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "3815 5000 0.763\n",
      "Test Accuracy\n",
      "7528 10000 0.7528\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet using Fine-Tuning')\n",
    "optimizer = torch.optim.Adam(finetune_model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, finetune_model, \"Alexnet Fine-Tuning\")\n",
    "print('Test Accuracy')\n",
    "accuracy(finetune_model, test_loader, 0, \"Alexnet Fine-Tuning Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0313dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet using Feature Extraction\n",
      "Epoch 1 [45/45] - Loss: 1.3447772264480594\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "2725 5000 0.545\n",
      "Epoch 2 [45/45] - Loss: 1.2082532644271857\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "2846 5000 0.5692\n",
      "Epoch 3 [45/45] - Loss: 1.1594625711441045\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "2914 5000 0.5828\n",
      "Epoch 4 [45/45] - Loss: 1.1182472705841064\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "2962 5000 0.5924\n",
      "Epoch 5 [45/45] - Loss: 1.0970376729965217\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "2956 5000 0.5912\n",
      "Epoch 6 [45/45] - Loss: 1.0950981378555298\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "2959 5000 0.5918\n",
      "Epoch 7 [45/45] - Loss: 1.0373317003250122\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "2973 5000 0.5946\n",
      "Epoch 8 [45/45] - Loss: 0.9490970373153687\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "2992 5000 0.5984\n",
      "Epoch 9 [45/45] - Loss: 0.9725825190544128\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "2968 5000 0.5936\n",
      "Epoch 10 [45/45] - Loss: 0.9403873085975647\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "3036 5000 0.6072\n",
      "Epoch 11 [45/45] - Loss: 0.8918799161911011\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "2998 5000 0.5996\n",
      "Epoch 12 [45/45] - Loss: 0.9329661726951599\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3000 5000 0.6\n",
      "Epoch 13 [45/45] - Loss: 0.8774821162223816\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3003 5000 0.6006\n",
      "Epoch 14 [45/45] - Loss: 0.8107404708862305\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "3000 5000 0.6\n",
      "Epoch 15 [45/45] - Loss: 0.7482171654701233\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3020 5000 0.604\n",
      "Epoch 16 [45/45] - Loss: 0.7936253547668457\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "3003 5000 0.6006\n",
      "Epoch 17 [45/45] - Loss: 0.7500815391540527\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "2964 5000 0.5928\n",
      "Epoch 18 [45/45] - Loss: 0.6829909682273865\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "2952 5000 0.5904\n",
      "Epoch 19 [45/45] - Loss: 0.6979635357856751\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "2987 5000 0.5974\n",
      "Epoch 20 [45/45] - Loss: 0.7382270693778992\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "2999 5000 0.5998\n",
      "Test Accuracy\n",
      "6008 10000 0.6008\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet using Feature Extraction')\n",
    "optimizer = torch.optim.Adam(featureextract_model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, featureextract_model, \"Alexnet Feature Extraction\")\n",
    "print('Test Accuracy')\n",
    "accuracy(featureextract_model, test_loader, 0, \"Alexnet Feature Extraction Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e84d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x))) # 28x28 > 14x14\n",
    "        x = self.pool(self.relu(self.conv2(x))) # 14x14 > 7x7\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "# Create an instance of the model\n",
    "model_mnist = Model()\n",
    "model_mnist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec766e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n",
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "112.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "train_dataset_mnist, val_dataset_mnist = random_split(train_dataset_mnist, [55000, 5000])\n",
    "test_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "\n",
    "train_loader_mnist = DataLoader(train_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "val_loader_mnist = DataLoader(val_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader_mnist = DataLoader(test_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60713319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN on MNIST dataset\n",
      "Epoch 1 [55/55] - Loss: 0.29157838225364685\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "4555 5000 0.911\n",
      "Epoch 2 [55/55] - Loss: 0.16047182679176334\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "4743 5000 0.9486\n",
      "Epoch 3 [55/55] - Loss: 0.12898932397365574\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "4809 5000 0.9618\n",
      "Epoch 4 [55/55] - Loss: 0.10024007409811028\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "4843 5000 0.9686\n",
      "Epoch 5 [55/55] - Loss: 0.07718485593795776\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "4875 5000 0.975\n",
      "Epoch 6 [55/55] - Loss: 0.049719043076038364\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "4883 5000 0.9766\n",
      "Epoch 7 [55/55] - Loss: 0.082723706960678146\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "4899 5000 0.9798\n",
      "Epoch 8 [55/55] - Loss: 0.045820534229278564\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "4907 5000 0.9814\n",
      "Epoch 9 [55/55] - Loss: 0.033197652548551564\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "4903 5000 0.9806\n",
      "Epoch 10 [55/55] - Loss: 0.049201369285583496\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "4907 5000 0.9814\n",
      "Test Accuracy:\n",
      "9874 10000 0.9874\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN on MNIST dataset')\n",
    "optimizer = torch.optim.Adam(model_mnist.parameters(), lr=0.001)\n",
    "train(epochs, optimizer, loss_fn, train_loader_mnist, val_loader_mnist, model_mnist, \"CNN MNIST\")\n",
    "print('Test Accuracy:')\n",
    "accuracy(model_mnist, test_loader_mnist, 0, \"CNN MNIST Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4168a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svhn = Model()\n",
    "model_svhn_finetune = copy.deepcopy(model_mnist)\n",
    "model_svhn_featureextract = copy.deepcopy(model_mnist)\n",
    "\n",
    "# freeze feature extraction (4 layers)\n",
    "for i, param in enumerate(model_svhn_featureextract.parameters()):\n",
    "    if i < 4:\n",
    "        param.requires_grad = False\n",
    "\n",
    "model_svhn.to(device)\n",
    "model_svhn_finetune.to(device)\n",
    "model_svhn_featureextract.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1e3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a465f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data\\train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data\\test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "train_dataset_svhn = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transforms)\n",
    "test_dataset_svhn = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transforms)\n",
    "\n",
    "train_dataset_svhn, val_dataset_svhn = random_split(train_dataset_svhn, [73257-10000, 10000])\n",
    "\n",
    "train_loader_svhn = DataLoader(train_dataset_svhn,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)                        \n",
    "\n",
    "val_loader_svhn = DataLoader(train_dataset_svhn,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)                        \n",
    "\n",
    "\n",
    "test_loader_svhn = DataLoader(test_dataset_svhn,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb1f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN on SVHN dataset\n",
      "Epoch 1 [64/64] - Loss: 2.2119908332824707\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "13724 63257 0.21695622618840602\n",
      "Epoch 2 [64/64] - Loss: 1.3105114698410034\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "36999 63257 0.5848996948954266\n",
      "Epoch 3 [64/64] - Loss: 0.9640682339668274\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "46267 63257 0.7314131242392147\n",
      "Epoch 4 [64/64] - Loss: 0.6737480759620667\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "49536 63257 0.7830911993929526\n",
      "Epoch 5 [64/64] - Loss: 0.8399789333343506\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "51161 63257 0.808780055962186\n",
      "Epoch 6 [64/64] - Loss: 0.6650354862213135\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "52305 63257 0.8268650109869263\n",
      "Epoch 7 [64/64] - Loss: 0.6380900740623474\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "52772 63257 0.834247593151746\n",
      "Epoch 8 [64/64] - Loss: 0.44524067640304565\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "53074 63257 0.8390217683418436\n",
      "Epoch 9 [64/64] - Loss: 0.47254526615142827\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "53340 63257 0.8432268365556381\n",
      "Epoch 10 [64/64] - Loss: 0.49648445844650275\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "53771 63257 0.8500403117441548\n",
      "Test Accuracy:\n",
      "21886 26032 0.8407344806392133\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN on SVHN dataset')\n",
    "optimizer = torch.optim.Adam(model_svhn.parameters(), lr=0.001)\n",
    "train(epochs, optimizer, loss_fn, train_loader_svhn, val_loader_svhn, model_svhn, \"CNN SVHN\")\n",
    "print('Test Accuracy:')\n",
    "accuracy(model_svhn, test_loader_svhn, 0, \"CNN SVHN Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f076c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN using Fine-Tuning from MNIST to SVHN dataset\n",
      "Epoch 1 [64/64] - Loss: 1.5334813594818115\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "35194 63257 0.556365303444678\n",
      "Epoch 2 [64/64] - Loss: 0.9767907261848451\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "45905 63257 0.7256904374219454\n",
      "Epoch 3 [64/64] - Loss: 0.7508372068405151\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "48419 63257 0.7654330746004395\n",
      "Epoch 4 [64/64] - Loss: 0.7203544974327087\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "50484 63257 0.7980776831022653\n",
      "Epoch 5 [64/64] - Loss: 0.7950326204299927\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "51643 63257 0.8163997660337986\n",
      "Epoch 6 [64/64] - Loss: 0.6251319050788879\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "51823 63257 0.8192453009153137\n",
      "Epoch 7 [64/64] - Loss: 0.6101942658424377\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "52500 63257 0.8299476737752344\n",
      "Epoch 8 [64/64] - Loss: 0.48871609568595886\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "52831 63257 0.8351802962517982\n",
      "Epoch 9 [64/64] - Loss: 0.6005406975746155\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "52989 63257 0.8376780435366837\n",
      "Epoch 10 [64/64] - Loss: 0.45568189024925234\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "53369 63257 0.8436852838421044\n",
      "Test Accuracy:\n",
      "22010 26032 0.8454978488014752\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN using Fine-Tuning from MNIST to SVHN dataset')\n",
    "optimizer = torch.optim.Adam(model_svhn_finetune.parameters(), lr=0.001)\n",
    "train(epochs, optimizer, loss_fn, train_loader_svhn, val_loader_svhn, model_svhn_finetune, \"CNN SVHN Fine-Tuning\")\n",
    "print('Test Accuracy:')\n",
    "accuracy(model_svhn_finetune, test_loader_svhn, 0, \"CNN SVHN Fine-Tuning Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35f6ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN using Feature Extraction from MNIST to SVHN dataset\n",
      "Epoch 1 [64/64] - Loss: 1.5267637968063354\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "31538 63257 0.4985693282956827\n",
      "Epoch 2 [64/64] - Loss: 1.3291512727737427\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "38867 63257 0.6144300235547054\n",
      "Epoch 3 [64/64] - Loss: 1.1845867633819587\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "43773 63257 0.6919866576031111\n",
      "Epoch 4 [64/64] - Loss: 1.0370007753372192\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "45473 63257 0.7188611537063092\n",
      "Epoch 5 [64/64] - Loss: 1.0482565164566045\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "46264 63257 0.7313656986578561\n",
      "Epoch 6 [64/64] - Loss: 0.8969573974609375\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "47036 63257 0.7435698815941318\n",
      "Epoch 7 [64/64] - Loss: 0.9260016083717346\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "48164 63257 0.7614019001849598\n",
      "Epoch 8 [64/64] - Loss: 0.8790746927261353\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "48262 63257 0.7629511358426735\n",
      "Epoch 9 [64/64] - Loss: 0.8984967470169067\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "48739 63257 0.7704918032786885\n",
      "Epoch 10 [64/64] - Loss: 0.7315301299095154\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "49428 63257 0.7813838784640436\n",
      "Test Accuracy:\n",
      "20603 26032 0.7914489858635525\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN using Feature Extraction from MNIST to SVHN dataset')\n",
    "optimizer = torch.optim.Adam(model_svhn_featureextract.parameters(), lr=0.001)\n",
    "train(epochs, optimizer, loss_fn, train_loader_svhn, val_loader_svhn, model_svhn_featureextract, \"CNN SVHN Feature Extraction\")\n",
    "print('Test Accuracy:')\n",
    "accuracy(model_svhn_featureextract, test_loader_svhn, 0, \"CNN SVHN Feature Extraction Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de08be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
