{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2363cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "torch.manual_seed(42)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d42f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('NO GPU AVAILABLE ERROR')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72165de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torchvision.models.alexnet(pretrained = False)\n",
    "pretrained_alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "featureextract_alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    torchvision.transforms.Resize((63,63)),\n",
    "    alexnet,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "finetune_model = nn.Sequential(\n",
    "    torchvision.transforms.Resize((63,63)),\n",
    "    pretrained_alexnet,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "featureextract_model = nn.Sequential(\n",
    "    torchvision.transforms.Resize((63,63)),\n",
    "    featureextract_alexnet,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "# freeze feature extraction (13 layers)\n",
    "for i, param in enumerate(featureextract_model.parameters()):\n",
    "    if i < 13:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c68bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, optimizer, loss_fn, train_loader, val_loader, model, name):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(data)\n",
    "            loss = loss_fn(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(f\"{name} Loss/train\", loss, epoch)\n",
    "            optimizer.zero_grad()\n",
    "            print(\n",
    "                f'\\rEpoch {epoch+1} [{i+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "                end=''\n",
    "            )\n",
    "\n",
    "        print('\\n*************************************')\n",
    "        print('Validation the model after epoch:', epoch)\n",
    "        accuracy(model, val_loader, epoch, f\"{name} Accuracy/validation\")\n",
    "\n",
    "def accuracy(model, data_loader, epoch, name):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, (data, labels) in enumerate(data_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(data)\n",
    "            for i in range(len(labels)):\n",
    "                pr = torch.argmax(pred[i], dim=-1)\n",
    "                if pr == labels[i]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        print(correct, total, correct/total)\n",
    "        writer.add_scalar(name, correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fd33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "finetune_model.to(device)\n",
    "featureextract_model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3935d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet from scratch\n",
      "Epoch 1 [45/45] - Loss: 2.2874557971954346\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "501 5000 0.1002\n",
      "Epoch 2 [45/45] - Loss: 1.9699366092681885\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "850 5000 0.17\n",
      "Epoch 3 [45/45] - Loss: 1.8583990335464478\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "1237 5000 0.2474\n",
      "Epoch 4 [45/45] - Loss: 1.7117093801498413\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "1598 5000 0.3196\n",
      "Epoch 5 [45/45] - Loss: 1.5909616947174072\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "1828 5000 0.3656\n",
      "Epoch 6 [45/45] - Loss: 1.4799968004226685\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "2184 5000 0.4368\n",
      "Epoch 7 [45/45] - Loss: 1.3030411005020142\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "2456 5000 0.4912\n",
      "Epoch 8 [45/45] - Loss: 1.2612520456314087\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "2532 5000 0.5064\n",
      "Epoch 9 [45/45] - Loss: 1.0791016817092896\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "2855 5000 0.571\n",
      "Epoch 10 [45/45] - Loss: 1.0829023122787476\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "2890 5000 0.578\n",
      "Epoch 11 [45/45] - Loss: 0.9198372960090637\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "3008 5000 0.6016\n",
      "Epoch 12 [45/45] - Loss: 0.9401163458824158\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3119 5000 0.6238\n",
      "Epoch 13 [45/45] - Loss: 0.8318465948104858\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3135 5000 0.627\n",
      "Epoch 14 [45/45] - Loss: 0.8324440717697144\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "3132 5000 0.6264\n",
      "Epoch 15 [45/45] - Loss: 0.7789023518562317\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3163 5000 0.6326\n",
      "Epoch 16 [45/45] - Loss: 0.6401512622833252\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "3209 5000 0.6418\n",
      "Epoch 17 [45/45] - Loss: 0.6189883947372437\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "3158 5000 0.6316\n",
      "Epoch 18 [45/45] - Loss: 0.5891289114952087\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "3200 5000 0.64\n",
      "Epoch 19 [45/45] - Loss: 0.46199625730514526\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "3217 5000 0.6434\n",
      "Epoch 20 [45/45] - Loss: 0.48484799265861517\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "3235 5000 0.647\n",
      "Test Accuracy\n",
      "6346 10000 0.6346\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet from scratch')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, model, \"Alexnet\")\n",
    "print('Test Accuracy')\n",
    "accuracy(model, test_loader, 0, \"Alexnet Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281d000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet using Fine-Tuning\n",
      "Epoch 1 [45/45] - Loss: 1.8595151901245117\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "1295 5000 0.259\n",
      "Epoch 2 [45/45] - Loss: 1.6950253248214722\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "1510 5000 0.302\n",
      "Epoch 3 [45/45] - Loss: 1.5712940692901611\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "2083 5000 0.4166\n",
      "Epoch 4 [45/45] - Loss: 1.3850033283233643\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "2618 5000 0.5236\n",
      "Epoch 5 [45/45] - Loss: 1.0774943828582764\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "3067 5000 0.6134\n",
      "Epoch 6 [45/45] - Loss: 1.1105445623397827\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "3080 5000 0.616\n",
      "Epoch 7 [45/45] - Loss: 0.9181387424468994\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "3448 5000 0.6896\n",
      "Epoch 8 [45/45] - Loss: 0.7831370830535889\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "3467 5000 0.6934\n",
      "Epoch 9 [45/45] - Loss: 0.7008203864097595\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "3619 5000 0.7238\n",
      "Epoch 10 [45/45] - Loss: 0.6489705443382263\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "3656 5000 0.7312\n",
      "Epoch 11 [45/45] - Loss: 0.46674606204032986\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "3768 5000 0.7536\n",
      "Epoch 12 [45/45] - Loss: 0.43570181727409363\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3750 5000 0.75\n",
      "Epoch 13 [45/45] - Loss: 0.32796651124954224\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3791 5000 0.7582\n",
      "Epoch 14 [45/45] - Loss: 0.36308696866035464\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "3791 5000 0.7582\n",
      "Epoch 15 [45/45] - Loss: 0.30788922309875496\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3728 5000 0.7456\n",
      "Epoch 16 [45/45] - Loss: 0.27324923872947693\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "3835 5000 0.767\n",
      "Epoch 17 [45/45] - Loss: 0.20568428933620453\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "3814 5000 0.7628\n",
      "Epoch 18 [45/45] - Loss: 0.17725144326686864\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "3860 5000 0.772\n",
      "Epoch 19 [45/45] - Loss: 0.23827499151229858\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "3739 5000 0.7478\n",
      "Epoch 20 [45/45] - Loss: 0.18938913941383362\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "3828 5000 0.7656\n",
      "Test Accuracy\n",
      "7619 10000 0.7619\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet using Fine-Tuning')\n",
    "optimizer = torch.optim.Adam(finetune_model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, finetune_model, \"Alexnet Fine-Tuning\")\n",
    "print('Test Accuracy')\n",
    "accuracy(finetune_model, test_loader, 0, \"Alexnet Fine-Tuning Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0313dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet using Feature Extraction\n",
      "Epoch 1 [45/45] - Loss: 1.3259660005569458\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "2726 5000 0.5452\n",
      "Epoch 2 [45/45] - Loss: 1.1977894306182861\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "2885 5000 0.577\n",
      "Epoch 3 [45/45] - Loss: 1.1058943271636963\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "2952 5000 0.5904\n",
      "Epoch 4 [45/45] - Loss: 1.1222182512283325\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "2950 5000 0.59\n",
      "Epoch 5 [45/45] - Loss: 1.1288565397262573\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "2977 5000 0.5954\n",
      "Epoch 6 [45/45] - Loss: 1.1508796215057373\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "3016 5000 0.6032\n",
      "Epoch 7 [45/45] - Loss: 1.0017836093902588\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "3035 5000 0.607\n",
      "Epoch 8 [45/45] - Loss: 1.0152449607849129\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "3029 5000 0.6058\n",
      "Epoch 9 [45/45] - Loss: 0.9487928152084351\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "3025 5000 0.605\n",
      "Epoch 10 [45/45] - Loss: 0.9051769971847534\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "3026 5000 0.6052\n",
      "Epoch 11 [45/45] - Loss: 0.9199008941650391\n",
      "*************************************\n",
      "Validation the model after epoch: 10\n",
      "3004 5000 0.6008\n",
      "Epoch 12 [45/45] - Loss: 0.8340781927108765\n",
      "*************************************\n",
      "Validation the model after epoch: 11\n",
      "3001 5000 0.6002\n",
      "Epoch 13 [45/45] - Loss: 0.8245988488197327\n",
      "*************************************\n",
      "Validation the model after epoch: 12\n",
      "3001 5000 0.6002\n",
      "Epoch 14 [45/45] - Loss: 0.8313643932342529\n",
      "*************************************\n",
      "Validation the model after epoch: 13\n",
      "2981 5000 0.5962\n",
      "Epoch 15 [45/45] - Loss: 0.8062652945518494\n",
      "*************************************\n",
      "Validation the model after epoch: 14\n",
      "3012 5000 0.6024\n",
      "Epoch 16 [45/45] - Loss: 0.8015248179435732\n",
      "*************************************\n",
      "Validation the model after epoch: 15\n",
      "2993 5000 0.5986\n",
      "Epoch 17 [45/45] - Loss: 0.7128000855445862\n",
      "*************************************\n",
      "Validation the model after epoch: 16\n",
      "3001 5000 0.6002\n",
      "Epoch 18 [45/45] - Loss: 0.7227844595909119\n",
      "*************************************\n",
      "Validation the model after epoch: 17\n",
      "2958 5000 0.5916\n",
      "Epoch 19 [45/45] - Loss: 0.6868190169334412\n",
      "*************************************\n",
      "Validation the model after epoch: 18\n",
      "2970 5000 0.594\n",
      "Epoch 20 [45/45] - Loss: 0.7029597163200378\n",
      "*************************************\n",
      "Validation the model after epoch: 19\n",
      "2945 5000 0.589\n",
      "Test Accuracy\n",
      "5949 10000 0.5949\n"
     ]
    }
   ],
   "source": [
    "print('Training AlexNet using Feature Extraction')\n",
    "optimizer = torch.optim.Adam(featureextract_model.parameters())\n",
    "train(epochs, optimizer, loss_fn, train_loader, val_loader, featureextract_model, \"Alexnet Feature Extraction\")\n",
    "print('Test Accuracy')\n",
    "accuracy(featureextract_model, test_loader, 0, \"Alexnet Feature Extraction Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e84d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x))) # 28x28 > 14x14\n",
    "        x = self.pool(self.relu(self.conv2(x))) # 14x14 > 7x7\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "# Create an instance of the model\n",
    "model_mnist = Model()\n",
    "model_mnist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec766e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "train_dataset_mnist, val_dataset_mnist = random_split(train_dataset_mnist, [55000, 5000])\n",
    "test_dataset_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "\n",
    "train_loader_mnist = DataLoader(train_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "val_loader_mnist = DataLoader(val_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader_mnist = DataLoader(test_dataset_mnist,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60713319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN on MNIST dataset\n",
      "Epoch 1 [55/55] - Loss: 0.32087275385856635\n",
      "*************************************\n",
      "Validation the model after epoch: 0\n",
      "4570 5000 0.914\n",
      "Epoch 2 [55/55] - Loss: 0.18869473040103912\n",
      "*************************************\n",
      "Validation the model after epoch: 1\n",
      "4759 5000 0.9518\n",
      "Epoch 3 [55/55] - Loss: 0.13600088655948646\n",
      "*************************************\n",
      "Validation the model after epoch: 2\n",
      "4840 5000 0.968\n",
      "Epoch 4 [55/55] - Loss: 0.10418694466352463\n",
      "*************************************\n",
      "Validation the model after epoch: 3\n",
      "4861 5000 0.9722\n",
      "Epoch 5 [55/55] - Loss: 0.057641424238681795\n",
      "*************************************\n",
      "Validation the model after epoch: 4\n",
      "4884 5000 0.9768\n",
      "Epoch 6 [55/55] - Loss: 0.061839338392019275\n",
      "*************************************\n",
      "Validation the model after epoch: 5\n",
      "4890 5000 0.978\n",
      "Epoch 7 [55/55] - Loss: 0.057130035012960434\n",
      "*************************************\n",
      "Validation the model after epoch: 6\n",
      "4898 5000 0.9796\n",
      "Epoch 8 [55/55] - Loss: 0.042169380933046346\n",
      "*************************************\n",
      "Validation the model after epoch: 7\n",
      "4905 5000 0.981\n",
      "Epoch 9 [55/55] - Loss: 0.049213275313377384\n",
      "*************************************\n",
      "Validation the model after epoch: 8\n",
      "4909 5000 0.9818\n",
      "Epoch 10 [55/55] - Loss: 0.038353931158781055\n",
      "*************************************\n",
      "Validation the model after epoch: 9\n",
      "4916 5000 0.9832\n",
      "Test Accuracy:\n",
      "9885 10000 0.9885\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN on MNIST dataset')\n",
    "optimizer = torch.optim.Adam(model_mnist.parameters(), lr=0.001)\n",
    "train(epochs, optimizer, loss_fn, train_loader_mnist, val_loader_mnist, model_mnist, \"CNN for MNIST\")\n",
    "print('Test Accuracy:')\n",
    "accuracy(model_mnist, test_loader_mnist, 0, \"CNN for MNIST Accuracy/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4168a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\eriks\\anaconda3\\envs\\d7047e\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in c:\\users\\eriks\\anaconda3\\envs\\d7047e\\lib\\site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ccd92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtest(model, test_loader):\n",
    "    correct, total = 0, 0\n",
    "    for _, (data, labels) in enumerate(test_loader):\n",
    "        data = torchvision.transforms.Resize((28,28))(torchvision.transforms.Grayscale()(data))\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "        for i in range(len(labels)):\n",
    "            pr = torch.argmax(pred[i], dim=-1)\n",
    "            if pr == labels[i]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(correct, total, correct/total)\n",
    "    writer.add_scalar(\"CNN for MNIST with SVHN data Accuracy/test\", correct/total, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a465f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\test_32x32.mat\n",
      "Test Accuracy (SVHN):\n",
      "5342 26032 0.20520897357098955\n"
     ]
    }
   ],
   "source": [
    "test_dataset_svhn = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=ToTensor())\n",
    "\n",
    "test_loader_svhn = DataLoader(test_dataset_svhn,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "print('Test Accuracy (SVHN):')\n",
    "runtest(model_mnist, test_loader_svhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1f098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
